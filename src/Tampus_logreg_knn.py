# -*- coding: utf-8 -*-
"""LogReg_KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VTs4cqfWPSwYJL8u1mKr2YORW8lPgq_v
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import label_binarize

# Load the data
df = pd.read_csv('../datasets/framingham_heart_disease.csv')

# Check for missing values
# print(df.isnull().sum())

# Impute missing values
imputer = SimpleImputer(strategy='mean')
df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

# Split data into features and target variable
# TenYearCHD = patient has developed coronary heart disease in 10 years
X = df_imputed.drop('TenYearCHD', axis=1)
y = df_imputed['TenYearCHD']

#Show Actual Data
print("X Actual Data")
print(X)
print("Y Actual Data")
print(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#Show Training and Test Data
plt.figure(figsize=(12, 8))

# Plot actual data distribution
plt.subplot(2, 2, 1)
sns.countplot(x='TenYearCHD', data=df_imputed)
plt.title('Actual Data Distribution')

# Plot training data distribution
plt.subplot(2, 2, 2)
sns.countplot(x=y_train)
plt.title('Training Data Distribution')

# Plot testing data distribution
plt.subplot(2, 2, 3)
sns.countplot(x=y_test)
plt.title('Testing Data Distribution')

# Using Logistic Regression
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
logreg_accuracy = accuracy_score(y_test, y_pred_logreg)
logreg_conf_matrix = confusion_matrix(y_test, y_pred_logreg)
logreg_report = classification_report(y_test, y_pred_logreg, output_dict=True)
print("Logistic Regression Accuracy:", logreg_accuracy)
print("Logistic Regression Confusion Matrix")
print(logreg_conf_matrix)
print("Logistic Regression Classification Report")
print(classification_report(y_test, y_pred_logreg))

# Plot confusion matrix for logistic regression
plt.subplot(2, 2, 4)
sns.heatmap(logreg_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No CHD', 'CHD'], yticklabels=['No CHD', 'CHD'])
plt.title('Logistic Regression Confusion Matrix')

plt.tight_layout()
plt.show()

# Plot classification report for logistic regression
plt.figure(figsize=(8, 6))
sns.heatmap(pd.DataFrame(logreg_report).iloc[:-1, :].T, annot=True, cmap='Blues')
plt.title('Logistic Regression Classification Report')
plt.show()

# Using KNN (K-Nearest Neighbors)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
knn_accuracy = accuracy_score(y_test, y_pred_knn)
knn_conf_matrix = confusion_matrix(y_test, y_pred_knn)
knn_report = classification_report(y_test, y_pred_knn, output_dict=True)
print("KNN Accuracy:", knn_accuracy)
print("KNN Confusion Matrix")
print(knn_conf_matrix)
print("KNN Classification Report")
print(classification_report(y_test, y_pred_knn))

# Plot confusion matrix for KNN
plt.figure(figsize=(8, 6))
sns.heatmap(knn_conf_matrix, annot=True, fmt='d', cmap='Greens', cbar=False,
            xticklabels=['No CHD', 'CHD'], yticklabels=['No CHD', 'CHD'])
plt.title('KNN Confusion Matrix')
plt.show()

# Plot classification report for KNN
plt.figure(figsize=(8, 6))
sns.heatmap(pd.DataFrame(knn_report).iloc[:-1, :].T, annot=True, cmap='Greens')
plt.title('KNN Classification Report')
plt.show()